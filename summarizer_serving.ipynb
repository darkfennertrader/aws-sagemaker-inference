{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9308328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet --upgrade pip\n",
    "!pip install --quiet -U sagemaker\n",
    "!pip install -U --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def9c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.13\n",
      "torch version: 1.7.1\n",
      "transformers version: 4.11.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "!python -V\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "362c0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb00e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://ai-inference-env/summarizer/model.tar.gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S3 directory where the model is stored\n",
    "bucket = \"ai-inference-env\"\n",
    "prefix = \"summarizer\"\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "pretrained_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c97edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m pipeline\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtest_cuda\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m test_cuda\n",
      "\n",
      "JSON_CONTENT_TYPE = \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# checking that cuda is available inside container\u001b[39;49;00m\n",
      "test_cuda()\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[36mprint\u001b[39;49;00m(model_dir)\n",
      "    summarizer = pipeline(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msummarization\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, model=model_dir, tokenizer=model_dir, framework=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, device=\u001b[34m0\u001b[39;49;00m\n",
      "    )\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m summarizer\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type=JSON_CONTENT_TYPE):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[36mtype\u001b[39;49;00m(serialized_input_data))\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == JSON_CONTENT_TYPE:\n",
      "        input_data = json.loads(serialized_input_data)\n",
      "        \u001b[34mreturn\u001b[39;49;00m input_data\n",
      "\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + content_type)\n",
      "        \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGot input Data: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(input_data))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model(input_data)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept=JSON_CONTENT_TYPE):\n",
      "    \u001b[34mif\u001b[39;49;00m accept == JSON_CONTENT_TYPE:\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(prediction_output), accept\n",
      "\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + accept)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fe99a",
   "metadata": {},
   "source": [
    " ### Deploy Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb1f2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance_type = \"local_gpu\" # or \"local\"\n",
    "instance_type = \"ml.g4dn.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "614b9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebb48c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=pretrained_model_data,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.1\",\n",
    "    source_dir=\"./code\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"inference.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0510551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(endpoint_name= \"summarizer\", initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44e46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaec461",
   "metadata": {},
   "source": [
    "### MODEL INFERENCE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a96203a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_to_summarize = \"When Paul Jobs was mustered out of the Coast Guard after World War II, he made a wager with his crewmates. They had arrived in San Francisco, where their ship was decommissioned, and Paul bet that he would find himself a wife within two weeks. He was a taut, tattooed engine mechanic, six feet tall, with a passing resemblance to James Dean. But it wasnâ€™t his looks that got him a date with Clara Hagopian, a sweet-humored daughter of Armenian immigrants. It was the fact that he and his friends had a car, unlike the group she had originally planned to go out with that evening. Ten days later, in March 1946, Paul got engaged to Clara and won his wager. It would turn out to be a happy marriage, one that lasted until death parted them more than forty years later.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c61a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Paul Jobs was mustered out of the Coast Guard after World War II . He bet that he would find himself a wife within two weeks . Ten days later, in March 1946, he got engaged to Clara Hagopian and won his wager . It would turn out to be a happy marriage, one that lasted until death .'}]\n",
      "\n",
      " Paul Jobs was mustered out of the Coast Guard after World War II . He bet that he would find himself a wife within two weeks . Ten days later, in March 1946, he got engaged to Clara Hagopian and won his wager . It would turn out to be a happy marriage, one that lasted until death .\n"
     ]
    }
   ],
   "source": [
    "result = predictor.predict(article_to_summarize)\n",
    "print(result)\n",
    "print()\n",
    "print(result[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cf0567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference on GPU is: 0.552 ms\n"
     ]
    }
   ],
   "source": [
    "inference_time = []\n",
    "for _ in range(30):\n",
    "    start = time.time()\n",
    "    predictor.predict(article_to_summarize)\n",
    "    inference_time.append(time.time()-start)\n",
    "    \n",
    "print(f\"Average inference on GPU is: {sum(inference_time)/len(inference_time):.3} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc805c",
   "metadata": {},
   "source": [
    "CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
